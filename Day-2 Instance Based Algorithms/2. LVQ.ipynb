{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b493b5-dbc9-4746-a510-d0139ac6a819",
   "metadata": {},
   "source": [
    "# Learining Vector Quantization (LVQ)\n",
    "\n",
    "A limitation of k-Nearest Neighbors is that you must keep a large database of training examples in order to make predictions.\n",
    "\n",
    "The Learning Vector Quantization algorithm addresses this by learning a much smaller subset of patterns that best represent the training data.\n",
    "\n",
    "### Steps\n",
    "\n",
    "- Euclidean Distance\n",
    "- Best Matching Unit\n",
    "- Training Codebook Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb987680-6362-4f7f-a371-8f079c32db54",
   "metadata": {},
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d39ddb-5d91-4edf-81d4-ca8fd29ae43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a357498-cce7-48bc-a6cd-bb63df330c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14cbf41-0834-4818-8fc8-f8f6c649bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[2.7810836,2.550537003,0],\n",
    "        [1.465489372,2.362125076,0],\n",
    "        [3.396561688,4.400293529,0],\n",
    "        [1.38807019,1.850220317,0],\n",
    "        [3.06407232,3.005305973,0],\n",
    "        [7.627531214,2.759262235,1],\n",
    "        [5.332441248,2.088626775,1],\n",
    "        [6.922596716,1.77106367,1],\n",
    "        [8.675418651,-0.242068655,1],\n",
    "        [7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab98eb1-5e80-4c70-9f36-764d85bf5bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.3290173915275787\n",
      "1.9494646655653247\n",
      "1.5591439385540549\n",
      "0.5356280721938492\n",
      "4.850940186986411\n",
      "2.592833759950511\n",
      "4.214227042632867\n",
      "6.522409988228337\n",
      "4.985585382449795\n"
     ]
    }
   ],
   "source": [
    "row0 = dataset[0]\n",
    "for row in dataset:\n",
    "    distance = euclidean_distance(row0, row)\n",
    "    print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e193e1d-9827-4b7c-8693-cf22ada687f4",
   "metadata": {},
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84279ad3-25f4-4063-ad72-ac45cb2dd7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_matching_unit(codebooks, test_row):\n",
    "    distances = list()\n",
    "    for codebook in codebooks:\n",
    "        dist = euclidean_distance(codebook, test_row)\n",
    "        distances.append((codebook, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    return distances[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1a5812-ff3a-4d2d-b57c-df2585b47004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7810836, 2.550537003, 0]\n"
     ]
    }
   ],
   "source": [
    "test_row = dataset[0]\n",
    "bmu = get_best_matching_unit(dataset, test_row)\n",
    "print(bmu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebda85a-d0b3-4580-bbdc-fbee921de233",
   "metadata": {},
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2821043-464a-499c-9329-524d0761dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7810836, 2.550537003, 0]\n"
     ]
    }
   ],
   "source": [
    "ctest_row = dataset[0]\n",
    "bmu = get_best_matching_unit(dataset, test_row)\n",
    "print(bmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eeb3f6a-eadf-4060-8605-9c186e3d7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_codebook(train):\n",
    "    n_records = len(train)\n",
    "    n_features = len(train[0])\n",
    "    codebook = [train[randrange(n_records)][i] for i in range(n_features)]\n",
    "    return codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75552883-b1b2-4fbb-af62-7f12568632c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_codebooks(train, n_codebooks, lrate, epochs):\n",
    "    codebooks = [random_codebook(train) for i in range(n_codebooks)]\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0-(epoch/float(epochs)))\n",
    "        sum_error = 0.0\n",
    "        for row in train:\n",
    "            bmu = get_best_matching_unit(codebooks, row)\n",
    "            for i in range(len(row)-1):\n",
    "                error = row[i] - bmu[i]\n",
    "                sum_error += error**2\n",
    "                if bmu[-1] == row[-1]:\n",
    "                    bmu[i] += rate * error\n",
    "                else:\n",
    "                    bmu[i] -= rate * error\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, rate, sum_error))\n",
    "    return codebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da4ba5c-d568-4e62-a281-754ee01f0a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.300, error=48.609\n",
      ">epoch=1, lrate=0.270, error=65.490\n",
      ">epoch=2, lrate=0.240, error=211.902\n",
      ">epoch=3, lrate=0.210, error=411.947\n",
      ">epoch=4, lrate=0.180, error=672.630\n",
      ">epoch=5, lrate=0.150, error=886.389\n",
      ">epoch=6, lrate=0.120, error=1106.568\n",
      ">epoch=7, lrate=0.090, error=1365.875\n",
      ">epoch=8, lrate=0.060, error=1509.847\n",
      ">epoch=9, lrate=0.030, error=1528.022\n",
      "Codebooks: [[16.226803378809347, 0.534610264137006, 1], [4.006090801809536, 18.36796337334561, 1]]\n"
     ]
    }
   ],
   "source": [
    "learn_rate = 0.3\n",
    "n_epochs = 10\n",
    "n_codebooks = 2\n",
    "codebooks = train_codebooks(dataset, n_codebooks, learn_rate, n_epochs)\n",
    "print('Codebooks: %s' % codebooks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
